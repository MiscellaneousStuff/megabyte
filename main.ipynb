{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta MegaByte Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 128\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BATCHES = int(1e5) - (2000 + 1700)\n",
    "BATCH_SIZE = 4\n",
    "GRADIENT_ACCUMULATE_EVERY = 4\n",
    "LEARNING_RATE = 2e-4\n",
    "VALIDATE_EVERY  = 100\n",
    "GENERATE_EVERY  = 500\n",
    "PRIME_LEN = 100\n",
    "SEQ_LEN = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle(loader):\n",
    "    while True:\n",
    "        for data in loader:\n",
    "            yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "with gzip.open('./data/enwik8.gz') as file:\n",
    "    # strip original to 95M?\n",
    "    x = np.frombuffer(file.read(int(95e6)), dtype=np.uint8).copy()\n",
    "\n",
    "    # 95M, 5M (train, valid)\n",
    "    train_x, valid_x = np.split(x, [int(90e6)])\n",
    "    data_train, data_val = map(torch.from_numpy, (train_x, valid_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class TextSamplerDataset(Dataset):\n",
    "    def __init__(self, data, seq_len):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        rand_start = torch.randint(0, self.data.size(0) - self.seq_len, (1,))\n",
    "        full_seq = self.data[rand_start: rand_start + self.seq_len].long()\n",
    "        return full_seq.cuda()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0) // self.seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextSamplerDataset(data_train, SEQ_LEN)\n",
    "val_dataset   = TextSamplerDataset(data_val, SEQ_LEN)\n",
    "train_loader  = cycle(DataLoader(train_dataset, batch_size = BATCH_SIZE))\n",
    "val_loader    = cycle(DataLoader(val_dataset, batch_size = BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decode_token(token):\n",
    "#     return str(chr(max(32, token)))\n",
    "\n",
    "def decode_token(token):\n",
    "    if 32 <= token <= 126:\n",
    "        return str(chr(token))\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def decode_tokens(tokens):\n",
    "    return ''.join(list(map(decode_token, tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = TextSamplerDataset(data_train, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' tires, a correct exhaust, and other street-legal items. The tech official (assuming the vehicle passes) will then use his white'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_tokens(txt[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Decoded Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"y:&amp;#945;&amp;#957;&amp;#945;&amp;#961;&amp;#967;&amp;#943;&amp;#945;|&amp;#945;&amp;#957;&amp;#945;&amp;#961;&amp;#967;&amp;#943;&amp;#945;]]'' (&quot;without [[archon]]s (ruler, chief, king)&quot;). Anarchism as a [[political philosophy]], is the belief that ''rulers'' are unnecessary and should be abolished, although there are differing interpretations of what this means. Anarchism also refers to related [[social movement]]s) that advocate the elimination of authoritarian institutions, par\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_tokens(x[5000:5500])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import megabyte\n",
    "\n",
    "model = megabyte.MEGABYTE(\n",
    "    num_tokens = 256,\n",
    "    dim = (768, 512, 256),\n",
    "    depth = (6, 4, 2),\n",
    "    max_seq_len = (512, 4, 4),\n",
    "    flash_attn = False\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8092/8092 [02:21<00:00, 57.14it/s]7,  1.43s/it]\n",
      "100%|██████████| 8092/8092 [02:17<00:00, 58.89it/s]2,  1.21s/it] \n",
      "100%|██████████| 8092/8092 [02:21<00:00, 57.31it/s]06,  1.26s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.65it/s]48,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.55it/s]2:01,  1.55s/it]\n",
      "100%|██████████| 8092/8092 [02:19<00:00, 58.01it/s]6:32,  1.24s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.53it/s]3:39,  1.36s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.62it/s]5:58,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:17<00:00, 58.71it/s]2:20,  1.21s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.95it/s]5:25,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:21<00:00, 56.99it/s]0:54,  1.26s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.93it/s]5:07,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.94it/s]5:23,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:21<00:00, 57.13it/s]7:32,  1.50s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.93it/s]0:24,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:21<00:00, 57.06it/s]9:02,  1.41s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.93it/s]2:47,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.92it/s]8:00,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.99it/s]5:51,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.63it/s]0:45,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.89it/s]17:45,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.83it/s]15:14,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.91it/s]13:35,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.22it/s]59:18,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:24<00:00, 56.17it/s]13:50,  1.30s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.41it/s]41:38,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:24<00:00, 56.14it/s]54:42,  1.30s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.30it/s]37:44,  1.30s/it] \n",
      "100%|██████████| 8092/8092 [02:24<00:00, 56.07it/s]26:28,  1.30s/it] \n",
      "100%|██████████| 8092/8092 [02:24<00:00, 56.13it/s]18:57,  1.30s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.34it/s]48:48,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:24<00:00, 56.06it/s]01:19,  1.30s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.38it/s]27:43,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:19<00:00, 58.05it/s]14:13,  1.24s/it] \n",
      "100%|██████████| 8092/8092 [02:19<00:00, 58.16it/s]41:43,  1.22s/it] \n",
      "100%|██████████| 8092/8092 [02:19<00:00, 58.14it/s]20:21,  1.21s/it] \n",
      "100%|██████████| 8092/8092 [02:18<00:00, 58.25it/s]14:22,  1.21s/it] \n",
      "100%|██████████| 8092/8092 [02:20<00:00, 57.77it/s]59:36,  1.21s/it] \n",
      "100%|██████████| 8092/8092 [02:18<00:00, 58.59it/s]54:41,  1.21s/it] \n",
      "100%|██████████| 8092/8092 [02:21<00:00, 57.13it/s]48:31,  1.26s/it] \n",
      "100%|██████████| 8092/8092 [02:21<00:00, 57.26it/s]33:55,  1.26s/it] \n",
      "100%|██████████| 8092/8092 [02:21<00:00, 57.20it/s]27:00,  1.26s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.75it/s]30:16,  1.52s/it] \n",
      "100%|██████████| 8092/8092 [02:24<00:00, 56.15it/s]07:44,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.20it/s]02:40,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.53it/s]:49:26,  1.27s/it]\n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.60it/s]:40:56,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:20<00:00, 57.55it/s]:26:34,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:19<00:00, 58.04it/s]:13:14,  1.21s/it] \n",
      "100%|██████████| 8092/8092 [02:34<00:00, 52.54it/s]:12:12,  1.47s/it] \n",
      "training:  26%|██▋       | 25448/96300 [11:09:31<31:04:03,  1.58s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21972/2113923753.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m__\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGRADIENT_ACCUMULATE_EVERY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'training loss: {loss.item()}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\win8t\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\win8t\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "with open('output.txt', 'w') as f:\n",
    "    with contextlib.redirect_stdout(f):\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
    "            model.train()\n",
    "\n",
    "            for __ in range(GRADIENT_ACCUMULATE_EVERY):\n",
    "                loss = model(next(train_loader), return_loss = True)\n",
    "                loss.backward()\n",
    "\n",
    "            print(f'training loss: {loss.item()}')\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "            if i % VALIDATE_EVERY == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    loss = model(next(val_loader), return_loss = True)\n",
    "                    print(f'validation loss: {loss.item()}')\n",
    "\n",
    "            if i != 0 and i % GENERATE_EVERY == 0:\n",
    "                model.eval()\n",
    "                inp = random.choice(val_dataset)[:-1]\n",
    "                prime_inp = inp[:PRIME_LEN]\n",
    "                prime = decode_tokens(prime_inp)\n",
    "                print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
    "\n",
    "                sample = model.generate(prime_inp[None, :])\n",
    "                sample = sample.flatten(1)\n",
    "\n",
    "                output_str = decode_tokens(sample[0][PRIME_LEN:])\n",
    "                try:\n",
    "                    print(output_str)\n",
    "                except:\n",
    "                    print(\"NOTE: ERROR DECODING STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./megabyte_25k_1.2836014032363892.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(optim.state_dict(), \"./megabyte(optim)_25k_1.2836014032363892.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(prompt, prompt_len=100):\n",
    "    model.eval()\n",
    "    prime_inp = inp[:prompt_len]\n",
    "    sample = model.generate(prime_inp[None, :])\n",
    "    sample = sample.flatten(1)\n",
    "\n",
    "    output_str = decode_tokens(sample[0][PRIME_LEN:])\n",
    "    print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8092/8092 [02:24<00:00, 55.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a confusion, an influence onew [[progressionative]] spanning, opponents of and free of a horistian claim of pages, and [[bategory]] forms oference during the [[15 years]] and the most expe color increaseduced to its promain of the early theory became org.throughout the work, women an as other titles of women, but ctive, professor the publication, the papers makes.  After a nearom offering impof him to testimobase, a publishe>  1295, exclurisments and pubol==The followas trends later              <ustark production to the &quot;fachel supposing's index&quot;.  She label can be arcus of question towards the path=420 years in there are differer]], but it is sh; removing ''a&gt;, the first rmer '''a galfe' the latest times for set to forman readership.  of [[Scotland]] about 17% to oveek half 100. Undy Paris.  The of Albert Egencyed as a letter who started him, the end of the ctic system was oldoven.  (Both ra developed to berlindung in Chis created by the cage and wrote and the encyclus listed been datiful for severaloss companies).*Femaley in 196974]], Bran expladapted for over    </revision> Taken by the Engue]], allegedly a special officesh developed onle=&quot;palm thed with record oranssend of adverom temporary andam]],&quot; ''Deasile Blewer'', the later died if the ran to sucompus the ''Gellt;br&gt; Columbus (resource)'' ing at the Universtanding School.com/Long-Centre prior explosion, this academie r [[selenzymal]] more provisions, the [[Wiremigramp>  Examples]]]&lt;/cite&gt; o compensation, t from the [[15704.77]] (2005) anists as or ''saroni mittoj'' it water there orgace.]]==A.C. (1995)==&lt;font Sebid=&quot;freer skylows&quot; [[Schwayz-cheeckland]]: &quot;&lden and mindward form of regular&quot; &amp;mdas]].This term d against Alsenhorg/ ''B. Jean Wopean, Jun Tive. cleanwieling,'' occupies Unix-Pr episodes 02.66*[http://www.usan philers.org/htar'' &quot;Documatic Tree&quot;, while scandal components]: Biow.documentation, when only monitords sport. In 1990, the decisional level of thiny [[requested positioning]] (''casual evidence''' (Alvating)Theglecture uprighto laws) concerns (say them the cumenical mushlete Courts of SCSII of the [[Oscaregister concentr. In Mac Octob|Such region]], [[http://www.ycddbuild.co.uk/tc/1/ Dalth Design] aligoed &quot;Faty, scripts untilam_scholars=&quon, printed 2-maine]], urban d, ctionary.===Ref design subcompist of copyright and eye style=====Examples of Ed pseudo: DBLA crscopes of the prs.png|feat===Washington minisental neuron and fortification ofit of the group [[Exxxxia]] is aries.Dr. Cereby and Furrender intended expandepcia's eyeculare publicity. Ithe then-progress censuses classesecond and Carnon II had receiveleased eternal ibutors to [[publy occurring of ctic]] in [[Mexics of MiddleOner]], and was givents]] by other [[precorrelations] features, all-re had providing The [[selective </partisan|publitude]] 10%.  Nevisions, overests. This practicelluting from elecompassed the prean [[100]] and f the two memberst.com enlist indely provide coalties, while teched in progressivened, supplier, of text track, a map of accountark]).==Improvitle>           was a small poig its advance&lt; showing at once mind.&lt;/cental id=0 [[Taxon by Reference]] </revision--nr. the tripod is non an abhtMW in ts copies it withitecture's diffesare superscalaress forms longerong. (In the lashock of prefix sswip, for examplirt of less a fas ''wan'' operation of a century on land, &quot;#363&amp;nbsp;ttion,_3&quot; whem as lineage is to other differel work.)== Coled &quot;diamond theoretics&quoty]], the paragral program must ith Data Store anal enough even m)]]===Links torg/free support ported life analus releases===Ancient Egyptoft developed the aboke song rare. Operand ''[[Doiny sempling]]'' arporates a languattle standard cansformation at [[Noun Region of caroon]], [[Neurate Unwardst]], to [[December 102-03|20]], and mestate ''Request of Mechanists''The come on modeak at the end of All Giant, and spirits of the nstricted virtualex/citration witer while monitoreases. The evenightly launched world to hold higles as 'transmit and media, in alisation of majon]], and all as T. Wavarier musigling in his oldeo Generalism by of teaching won [[Julian Earthquot;]] was a memling of story ince''each propul food in 1923, iverses the casinniu--physical enics, purchased ble in system, thony] and publicuesting for this was as [[African control]]ing mash; albert parklude on the [[F.    = 2010 countreduction for a l entire]] termin ratio of the fions of light. Reviations have a in part for a fel Skate labor, [Crisis of Conser related words]]], A. Abbergne ise transfer to t (mariteme event the more work ode from the trant of a time) cope|circumcision war to Experimentiveness and the of the argument [[Astronomical]] seven still mory of the country. Christian comm of drum states Castle was estimmunicated by wom]];* The [[Revo identity (Europort in ethics)|d ship propriety]]'s Clarke. The hydrogen articled in front of thomson. Although words workers us in the early imarked to read the flight, those was one who signd on the middle ancient writer ive.# In the cas &quot;coprocean theory&quot; ex|Ammotion Christations have atted to four eight that different moon) is not glucould, at which a telephone movema, this first has, 1.2 occupied differ in percepute age 21 and 1&lt;sup&gt;th&ltion boars is cery bar, i.e. the  <comment>/worrion of an early st of the Earth. to spacecraft al god-racing absor at a simple an [[Transcription system]].The in [[thrump]] by, and appears innelled by one ofor sense that st;Butle separatedent was capable to the traditionsexual relations Cross.  Ciable and past overheansgender abuse p://online.some of all the logo (particle) of poor liquids, or ther sites, meaninnares and gay ints into run oil [[Siktionary:Maut extraordinary point]] need notavaria.&lt;!-- Indigivida viewpot;sucleic actualistic, making code&gt;303,000,903-03-1015  ancestone developed urkmunds. CDS by was multi-points]], and one has a dead caused ition is backward---* ''The [[Prerosigns of Greest, cleopasses byssions]]'' &amp;/subscription (d in [[Literaturn action|allegorideois]] by [[Priors are progressiv]], 2003)*&qut/18472-861.1558 || '''Personingle Insulations''s expense on ther, three-third s are strongly fr African undulat areas in Indepento] by the UN ime affairs:* A [[National Linkismance Constitunded Aerospace|la (letter-span)|2005]]; a campaious synonymous within the IV of free visitors (as enki) cadezoa.)*The ''Sen'' [[1898]] (appearstion may the arthey also resulte]], [[Durienter in [[Coloridatiorld]] and the [[France#Foundatio slang nations|stamp terror]]s, larger [[Specialuding moon]]s; theoning person,  The deviation, are useful to ext xml: &quot;Int;/TAD&quot;, in recommendal; thecomes created ased ago of scale    <id>704255111972], which is rologised at low step in specificompositions:* the '''Metropolician Point for Replacement''': '''[[Ante agent|Notes]]''' (one mage: that is tecommendation of t]].  '''The frem. Hard Aberiesth a progressive (1988):''' [httpreversion.lin.tin it.leburg-stephy]]* [[Ecology]] [http://www.cond set.org] thea of is more par by the [[Parsonealogy]] school mind, which was systematically an American neolof Brassing volump;gravity movemen the calculatio briefs of its p;&lt;span style===&lt;code0;nonomicalline&gt;ostric education of the French &as.)* [[Rinalecthe [[Pizara]] (External links).* Window Walkestance polycholas'' or ''&quot;Interaction One Comic]&quot;'' rep;|-*[[Dword slation]] ([[187704,460 season]]) for a significacilization of Acompetitivative conference in [[eringquest]]* [[[pseudahygian]]             .* information for on [[animal]]: ctions also incluot; ([[help skeprogram]] linkwisorghones from [[Snatz]], [[Tuanes, wars|Subsequer thesis]])* [[[epischer]] (seesemblance among Adell System, clso hallow chauce]] in the early of comments up while the assembl spectrum [[Camb] ([[Glam Historonment|Stage]]) cognate with [[Roman and Studie\n"
     ]
    }
   ],
   "source": [
    "pred(\"hi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
