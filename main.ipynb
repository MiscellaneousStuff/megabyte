{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta MegaByte Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 128\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BATCHES = int(1e5) - (2000 + 1700)\n",
    "BATCH_SIZE = 4\n",
    "GRADIENT_ACCUMULATE_EVERY = 4\n",
    "LEARNING_RATE = 2e-4\n",
    "VALIDATE_EVERY  = 100\n",
    "GENERATE_EVERY  = 500\n",
    "PRIME_LEN = 100\n",
    "SEQ_LEN = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle(loader):\n",
    "    while True:\n",
    "        for data in loader:\n",
    "            yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "with gzip.open('./data/enwik8.gz') as file:\n",
    "    # strip original to 95M?\n",
    "    x = np.frombuffer(file.read(int(95e6)), dtype=np.uint8).copy()\n",
    "\n",
    "    # 95M, 5M (train, valid)\n",
    "    train_x, valid_x = np.split(x, [int(90e6)])\n",
    "    data_train, data_val = map(torch.from_numpy, (train_x, valid_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class TextSamplerDataset(Dataset):\n",
    "    def __init__(self, data, seq_len):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        rand_start = torch.randint(0, self.data.size(0) - self.seq_len, (1,))\n",
    "        full_seq = self.data[rand_start: rand_start + self.seq_len].long()\n",
    "        return full_seq.cuda()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0) // self.seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextSamplerDataset(data_train, SEQ_LEN)\n",
    "val_dataset   = TextSamplerDataset(data_val, SEQ_LEN)\n",
    "train_loader  = cycle(DataLoader(train_dataset, batch_size = BATCH_SIZE))\n",
    "val_loader    = cycle(DataLoader(val_dataset, batch_size = BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decode_token(token):\n",
    "#     return str(chr(max(32, token)))\n",
    "\n",
    "def decode_token(token):\n",
    "    if 32 <= token <= 126:\n",
    "        return str(chr(token))\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def decode_tokens(tokens):\n",
    "    return ''.join(list(map(decode_token, tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = TextSamplerDataset(data_train, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' tires, a correct exhaust, and other street-legal items. The tech official (assuming the vehicle passes) will then use his white'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_tokens(txt[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Decoded Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"y:&amp;#945;&amp;#957;&amp;#945;&amp;#961;&amp;#967;&amp;#943;&amp;#945;|&amp;#945;&amp;#957;&amp;#945;&amp;#961;&amp;#967;&amp;#943;&amp;#945;]]'' (&quot;without [[archon]]s (ruler, chief, king)&quot;). Anarchism as a [[political philosophy]], is the belief that ''rulers'' are unnecessary and should be abolished, although there are differing interpretations of what this means. Anarchism also refers to related [[social movement]]s) that advocate the elimination of authoritarian institutions, par\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_tokens(x[5000:5500])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import megabyte\n",
    "\n",
    "model = megabyte.MEGABYTE(\n",
    "    num_tokens = 256,\n",
    "    dim = (768, 512, 256),\n",
    "    depth = (6, 4, 2),\n",
    "    max_seq_len = (512, 4, 4),\n",
    "    flash_attn = False\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8092/8092 [02:21<00:00, 57.14it/s]7,  1.43s/it]\n",
      "100%|██████████| 8092/8092 [02:17<00:00, 58.89it/s]2,  1.21s/it] \n",
      "100%|██████████| 8092/8092 [02:21<00:00, 57.31it/s]06,  1.26s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.65it/s]48,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.55it/s]2:01,  1.55s/it]\n",
      "100%|██████████| 8092/8092 [02:19<00:00, 58.01it/s]6:32,  1.24s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.53it/s]3:39,  1.36s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.62it/s]5:58,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:17<00:00, 58.71it/s]2:20,  1.21s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.95it/s]5:25,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:21<00:00, 56.99it/s]0:54,  1.26s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.93it/s]5:07,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.94it/s]5:23,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:21<00:00, 57.13it/s]7:32,  1.50s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.93it/s]0:24,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:21<00:00, 57.06it/s]9:02,  1.41s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.93it/s]2:47,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.92it/s]8:00,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.99it/s]5:51,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.63it/s]0:45,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.89it/s]17:45,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.83it/s]15:14,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.91it/s]13:35,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.22it/s]59:18,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:24<00:00, 56.17it/s]13:50,  1.30s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.41it/s]41:38,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:24<00:00, 56.14it/s]54:42,  1.30s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.30it/s]37:44,  1.30s/it] \n",
      "100%|██████████| 8092/8092 [02:24<00:00, 56.07it/s]26:28,  1.30s/it] \n",
      "100%|██████████| 8092/8092 [02:24<00:00, 56.13it/s]18:57,  1.30s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.34it/s]48:48,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:24<00:00, 56.06it/s]01:19,  1.30s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.38it/s]27:43,  1.28s/it] \n",
      "100%|██████████| 8092/8092 [02:19<00:00, 58.05it/s]14:13,  1.24s/it] \n",
      "100%|██████████| 8092/8092 [02:19<00:00, 58.16it/s]41:43,  1.22s/it] \n",
      "100%|██████████| 8092/8092 [02:19<00:00, 58.14it/s]20:21,  1.21s/it] \n",
      "100%|██████████| 8092/8092 [02:18<00:00, 58.25it/s]14:22,  1.21s/it] \n",
      "100%|██████████| 8092/8092 [02:20<00:00, 57.77it/s]59:36,  1.21s/it] \n",
      "100%|██████████| 8092/8092 [02:18<00:00, 58.59it/s]54:41,  1.21s/it] \n",
      "100%|██████████| 8092/8092 [02:21<00:00, 57.13it/s]48:31,  1.26s/it] \n",
      "100%|██████████| 8092/8092 [02:21<00:00, 57.26it/s]33:55,  1.26s/it] \n",
      "100%|██████████| 8092/8092 [02:21<00:00, 57.20it/s]27:00,  1.26s/it] \n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.75it/s]30:16,  1.52s/it] \n",
      "100%|██████████| 8092/8092 [02:24<00:00, 56.15it/s]07:44,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.20it/s]02:40,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:23<00:00, 56.53it/s]:49:26,  1.27s/it]\n",
      "100%|██████████| 8092/8092 [02:22<00:00, 56.60it/s]:40:56,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:20<00:00, 57.55it/s]:26:34,  1.27s/it] \n",
      "100%|██████████| 8092/8092 [02:19<00:00, 58.04it/s]:13:14,  1.21s/it] \n",
      "100%|██████████| 8092/8092 [02:34<00:00, 52.54it/s]:12:12,  1.47s/it] \n",
      "training:  26%|██▋       | 25448/96300 [11:09:31<31:04:03,  1.58s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21972/2113923753.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m__\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGRADIENT_ACCUMULATE_EVERY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'training loss: {loss.item()}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\win8t\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\win8t\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "with open('output.txt', 'w') as f:\n",
    "    with contextlib.redirect_stdout(f):\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
    "            model.train()\n",
    "\n",
    "            for __ in range(GRADIENT_ACCUMULATE_EVERY):\n",
    "                loss = model(next(train_loader), return_loss = True)\n",
    "                loss.backward()\n",
    "\n",
    "            print(f'training loss: {loss.item()}')\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "            if i % VALIDATE_EVERY == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    loss = model(next(val_loader), return_loss = True)\n",
    "                    print(f'validation loss: {loss.item()}')\n",
    "\n",
    "            if i != 0 and i % GENERATE_EVERY == 0:\n",
    "                model.eval()\n",
    "                inp = random.choice(val_dataset)[:-1]\n",
    "                prime_inp = inp[:PRIME_LEN]\n",
    "                prime = decode_tokens(prime_inp)\n",
    "                print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
    "\n",
    "                sample = model.generate(prime_inp[None, :])\n",
    "                sample = sample.flatten(1)\n",
    "\n",
    "                output_str = decode_tokens(sample[0][PRIME_LEN:])\n",
    "                try:\n",
    "                    print(output_str)\n",
    "                except:\n",
    "                    print(\"NOTE: ERROR DECODING STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./megabyte_25k_1.2836014032363892.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(optim.state_dict(), \"./megabyte(optim)_25k_1.2836014032363892.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Param Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Millions of params: 52.10624\n"
     ]
    }
   ],
   "source": [
    "from megabyte import reduce_mult\n",
    "param_cnt = 0\n",
    "for parameter in model.parameters():\n",
    "    cur_param_cnt = reduce_mult(parameter.shape)\n",
    "    param_cnt += cur_param_cnt\n",
    "print(\"Millions of params:\", param_cnt / 1e6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(prompt, prompt_len=100):\n",
    "    model.eval()\n",
    "    prime_inp = inp[:prompt_len]\n",
    "    sample = model.generate(prime_inp[None, :])\n",
    "    sample = sample.flatten(1)\n",
    "\n",
    "    output_str = decode_tokens(sample[0][PRIME_LEN:])\n",
    "    print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8092/8092 [03:10<00:00, 42.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " two volumes including [[Triporation]]s.  The:GIG not home verence: ''b. moleactive'', the land as sphere as sidese defence. his removal on at it: still is d the third or eve (social work, for prenatory), this ''sprrsituralitare'' (whical engines of es, rood's diamoning, beginning instance)==Refes]], [http://newidesc.edu/europet's Diah Kebby]&lt;!-- Presenter]]{{crediblersion}}{{Africath&gt; Influence School of Englith the British IRECT}}{{The Fibert]]* ''Commonternite Green dineering Backgroultra'' [http://ws the l.org.uk/h (iblic education theory])* [[John Lake Punk]]   <title=Dnd Prinusa (''[http://www.bankline.inf episode, see a Spain and Perfecail]'')* [[Herment.]] ''(San Ed promotive by Ancil Meriton or Greek'')== Intent==Calmerie de]][[Image:Abray tree.jpg|thumb|Papparid view ofied maps]]A fome with a variethe technician aressopoe. [[Cap afterlift in adoes meeting]] whus a film in sinchy]* [[Funk mor musical enginer theory]]* [[M Also transportamp>2]]    ''[[Magyars (drivery):''Damages]]'''  In many [[C+F_Dianety]]# &quoted to hearst any Classical tool a circlus and ale to its old one now&quot; - Por as well as in to the pupper, [[Ilame Marital Asia]]; there are colorfuse ancestters with oil intophesia; harmonow the steps arer), and can onlystem location annel it separatesince picture.* and dexterature largest tuddy (of which is [[Brir name|ED]]). Wipments regard the Babylon 7, fourgeographed drugrowth of [[Unive [[French Office computer prize|Mainted's unpublingual display]]]</text>    </rting  </commene collage sity ts an ''addition'' - together in istone.* [[Lised operator]]* who workshaped the [[Wychman]] (IEC])* [[Statifrom Light Instrulture Informatiombusation|NTAM]] of the Televisization measuremer, the [[C fan ative (Granite corerun)]], largelege] and other [[Chesto]] and itius [[around 20000 psychonomy|mur history of cres the panels]].In [[database]][[latin alphabegislation]] cons that keep [[streplioar case]]. abowever the topan&quot; are cometa left.[http:Anglepredeath.phad a type.net a [[Romeone from tains]] named A tic P newsleave. the modern modalso belong to thef&gt;[http://wwwlingled.org.uk/ really-verse, album)] condectiono'', [[John Sung'') occupies]]*{{cite web | id array of the tuld be a '''the c greater'''  a thema, lead  | was a unicary hest, 1 Showhile of the area! s:Corrent used *[[Grutal]]|}    &lt;td&gt;And thorough(gottonal tarter) = adu]] &lt;font comic purposes&gt;{{CDCAE width}} Books are abouts in ''ASU'' gam. [[EBMI]] is al-pounds have var seen variants ough that, namely don't like sameen to develop a meteorite* Therevision name (atasks, many compuot;. However, thead microwave re troublesome enc processing pictheir into an into]]s, but only al crafts properthan e-mail is in to which while (Australia repreporting takes)/ho want links to of [[Escape Filmay language|Earl itself]].  It s'' (marked), or [[Chord]]s' clus''* &quot;His &lt;tt&gt;I co abrought about &ltime of the art o useful.&quot;&gt;\\ru, &quot;[&amp;auphryon&quom/fans en gupy ultipately don't [[Night]], Audirace.&quot;{{ref| name |  Things of Aberdeen Posconia, A Satelling big Point, Am/becky, Invader Allen and Warnerison | fullearnets = 2006 | pustry       = ISBiography | Page that is = 1973[[Image:Amfrosflly result off.pnfall.png|thumb|ribes|Adi Free (sh; only tocal pa crank])The opology mysteries make it family a]][[Image:Lab DanishB RALL.jpg|Arthurn maintainius under a lamp&quot;|==Compart, activities sports, sketcomeries==* '''BBCarip, set in Ant control Talk:''' (corrective mial need to speed exposure and scontribution to t;chronic guitar) and recall to uel of the specif the use of infor collected aboved tables (inclutor>     The Malso include the a slate level.#########   &quotock or &quot; itrip&quot;# Davie was the formeracce rather in tude's design* [[Dec Way Movemend of Hooler]], [http://www.instith alleriance.ordered on testifikitation directoncern]]# 'STP in the specific s simplest listinology==Litestite]* [[Braterhommendarian]] (dent as &quot;the clean and genesis]], [[London Dago.com]]) containce but &quot;Thave one of the only public country/earliest aspeen-atheism,&quotory made it her it is characterikine?) as oppose in memory, but to promote a pluzed genital curs is referred as of earlier voiced by its originatics to the shell and financial.  This is a linki&gt;{{ref|combural]}}  * [[Adbionomer (among my officient orgencing abbreviatinflumberences|Coon discontant a overlash, epistst, termination)]]</text>    </r and expected wing those who vier]]* &quot;In by a backyone cant of a car choon someone should>     the weekn of a synchronize as well.==Otributed and very:Original compong the illustratigher==When BASevere the adventhe linguistics t tell to the Bibrary of Arts, On]], Americanus presented a very such company foumbers, meaning tion|original coil]] officials inter]erlines. Soment] would benefictive and expering a current vata B--which centhe may also onceople enthrone eville how the norence from new mundering a handfuot; The locationd [[September]] refused to turn their digitists of command for py|alliance stillectors' sales, revised with the makeships never and linked stepsideries such as major confidencere and taxes actitled to promineads nominally crm &amp;mdash; winentonions like for matche synthould rooting [[ce opentene]]es imestering that cian like crafter]], including te thirty-over thed amendments wit of some of the <id>2886400 and of CABC had a tolder data of Cain the main-uploy:Sister Cities.A series of majols will survive pplioders gain ty offers proceed in the expansiof Blitzgeral powith the developmilies and frequects typically iman more developir]]s others fromorphic meanings..]]The UK Collement department the vicibal tim temporum sold ww.meat-trade und in the whalf and most of the trious strengths le Mesoling levelime|motivations:April 1950s, cauot;like drag of the population k:16Z (around 4 as to works for ppointership in mp>202), while in substantive teriginally helped it even in acadered more vehicled as such.Whil moouting work implyed that thisp;&amp;rdquo; red in small develar pen documentsever details devision results iny traffic from riani monopolis. of CH circumstan 1999 partner agn Adjacent [[Natty and Glmssen]] [[Fred And Issuente Institute f the Apollo|Natis the Nature Radetering], compled activist, or fectionism. Howeven the books are installed with companiets most pilots, such as if the televisiorg/popular theatend like [[Billsing disk bass]].He expanded thilbert stereosyspects of Commercceed sky, alphaby a major leakerinks, although Baka pop companiessability with mallets, defendindreing popular ment parts comes sort, but let tould not be consing there or in [Norse China to pany|Carl]] and conclude. Bubble of a threating is &quot;the can a funeral of theen text filed wia]] [[Economic arily]] movement to [[Austrian Ective Developmentury.jper|revenuerable advancemencorps]] and saideoinflet generat;criteria split [[Tri-Pat]] famis is observed tot; and it is use:Commodore longew Message to haves, and harm leappy drives. Counce folk page doent.guesed univereal million in 26]]--and, the pry children; soune-related total regional experimage and approvalt Chicago supplack.]]Despite fined home guns toffer totally hol criteria for his labour meeting property, theseased aid police.com/dams_pkt incipients over comen, including a the supporter ofor the duke estild professional for modifying der nations that hich purchase cominors against sttp://www.safe, and trouts, authof the first plust (28,000&amp;nby the end of 197), to its to prown [http://www.ch cripping machion, and way it instructions.] --0, 1,000,000 alon]], six laws findive and not ab. [[Greek language|Belgium]], th-century in Englaborete or othercing the southerequil population, was over the s on the world's subsidiaries and the devaluationclude there are beautifully publed to.==Charge regular credits=={{main|Marxis from our livinging classes in \n"
     ]
    }
   ],
   "source": [
    "pred(\"Machine learning [[Algorithm|algorithms]] build a model based on sample data, known as [[training data]], in order to make predictions or decisions without being explicitly programmed to do so.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52.10624, 'M')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Return the number of parameters in the model.\n",
    "For non-embedding count (default), the position embeddings get subtracted.\n",
    "The token embeddings would too, except due to the parameter sharing these\n",
    "params are actually used as weights in the final layer, so we include them.\n",
    "\"\"\"\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "# if non_embedding:\n",
    "#     n_params -= self.transformer.wpe.weight.numel()\n",
    "#     return n_params\n",
    "n_params / 1e6, \"M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([768]),\n",
       " torch.Size([512]),\n",
       " torch.Size([256]),\n",
       " torch.Size([256, 256]),\n",
       " torch.Size([256, 256]),\n",
       " torch.Size([1024]),\n",
       " torch.Size([1024]),\n",
       " torch.Size([512, 1024]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([256, 256]),\n",
       " torch.Size([4096]),\n",
       " torch.Size([4096]),\n",
       " torch.Size([768, 4096]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([512, 768]),\n",
       " torch.Size([128, 768]),\n",
       " torch.Size([768, 512]),\n",
       " torch.Size([768]),\n",
       " torch.Size([3072, 768]),\n",
       " torch.Size([3072]),\n",
       " torch.Size([768, 3072]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([512, 768]),\n",
       " torch.Size([128, 768]),\n",
       " torch.Size([768, 512]),\n",
       " torch.Size([768]),\n",
       " torch.Size([3072, 768]),\n",
       " torch.Size([3072]),\n",
       " torch.Size([768, 3072]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([512, 768]),\n",
       " torch.Size([128, 768]),\n",
       " torch.Size([768, 512]),\n",
       " torch.Size([768]),\n",
       " torch.Size([3072, 768]),\n",
       " torch.Size([3072]),\n",
       " torch.Size([768, 3072]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([512, 768]),\n",
       " torch.Size([128, 768]),\n",
       " torch.Size([768, 512]),\n",
       " torch.Size([768]),\n",
       " torch.Size([3072, 768]),\n",
       " torch.Size([3072]),\n",
       " torch.Size([768, 3072]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([512, 768]),\n",
       " torch.Size([128, 768]),\n",
       " torch.Size([768, 512]),\n",
       " torch.Size([768]),\n",
       " torch.Size([3072, 768]),\n",
       " torch.Size([3072]),\n",
       " torch.Size([768, 3072]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([512, 768]),\n",
       " torch.Size([128, 768]),\n",
       " torch.Size([768, 512]),\n",
       " torch.Size([768]),\n",
       " torch.Size([3072, 768]),\n",
       " torch.Size([3072]),\n",
       " torch.Size([768, 3072]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512, 512]),\n",
       " torch.Size([128, 512]),\n",
       " torch.Size([512, 512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([2048, 512]),\n",
       " torch.Size([2048]),\n",
       " torch.Size([512, 2048]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512, 512]),\n",
       " torch.Size([128, 512]),\n",
       " torch.Size([512, 512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([2048, 512]),\n",
       " torch.Size([2048]),\n",
       " torch.Size([512, 2048]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512, 512]),\n",
       " torch.Size([128, 512]),\n",
       " torch.Size([512, 512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([2048, 512]),\n",
       " torch.Size([2048]),\n",
       " torch.Size([512, 2048]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512, 512]),\n",
       " torch.Size([128, 512]),\n",
       " torch.Size([512, 512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([2048, 512]),\n",
       " torch.Size([2048]),\n",
       " torch.Size([512, 2048]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([256]),\n",
       " torch.Size([512, 256]),\n",
       " torch.Size([128, 256]),\n",
       " torch.Size([256, 512]),\n",
       " torch.Size([256]),\n",
       " torch.Size([1024, 256]),\n",
       " torch.Size([1024]),\n",
       " torch.Size([256, 1024]),\n",
       " torch.Size([256]),\n",
       " torch.Size([256]),\n",
       " torch.Size([512, 256]),\n",
       " torch.Size([128, 256]),\n",
       " torch.Size([256, 512]),\n",
       " torch.Size([256]),\n",
       " torch.Size([1024, 256]),\n",
       " torch.Size([1024]),\n",
       " torch.Size([256, 1024]),\n",
       " torch.Size([256]),\n",
       " torch.Size([256]),\n",
       " torch.Size([2048, 768]),\n",
       " torch.Size([2048]),\n",
       " torch.Size([1024, 512]),\n",
       " torch.Size([1024]),\n",
       " torch.Size([256, 256]),\n",
       " torch.Size([256])]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in model.parameters()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
